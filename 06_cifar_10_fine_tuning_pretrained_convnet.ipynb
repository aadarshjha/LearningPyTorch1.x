{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_cifar-10_fine_tuning_pretrained_convnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningPyTorch1.x/blob/master/06_cifar_10_fine_tuning_pretrained_convnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjOYtsNSQwiP",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR-10: Fine-tuning a pre-trained convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acNSIzr1Ngl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LigM_8TTHum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('PyTorch version:', torch.__version__)\n",
        "print('Torchvision version:', torchvision.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbJfT52eTXYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "train_set = CIFAR10('./cifar10', train=True, download=True, transform=dataset_transform)\n",
        "valid_set = CIFAR10('./cifar10', train=False, download=True, transform=dataset_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93LJtGTXIVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=128, num_workers=0, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=512, num_workers=0, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWDhCCtIyw_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    \n",
        "    train_batch_losses = []\n",
        "    \n",
        "    for batch, labels in train_loader:\n",
        "        batch = batch.to(cuda)\n",
        "        labels = labels.to(cuda)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(batch)\n",
        "        loss = loss_fn(y_pred, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_batch_losses.append(float(loss))\n",
        "        \n",
        "        mean_loss = statistics.mean(train_batch_losses)\n",
        "        \n",
        "    return mean_loss\n",
        "\n",
        "def validate(model, loss_fn, optimizer):\n",
        "    model.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        validation_batch_losses = []\n",
        "        \n",
        "        for batch, labels in valid_loader:\n",
        "            batch = batch.to(cuda)\n",
        "            labels = labels.to(cuda)\n",
        "            \n",
        "            labels_pred = model(batch)\n",
        "            loss = loss_fn(labels_pred, labels)\n",
        "            \n",
        "            validation_batch_losses.append(float(loss))\n",
        "            \n",
        "            mean_loss = statistics.mean(validation_batch_losses)\n",
        "            \n",
        "    return mean_loss\n",
        "\n",
        "def accuracy(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch, labels in loader:\n",
        "            batch = batch.to(cuda)\n",
        "            labels = labels.to(cuda)\n",
        "        \n",
        "            labels_pred = model(batch)\n",
        "        \n",
        "            _, predicted = torch.max(labels_pred.data, 1)\n",
        "        \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "        \n",
        "    return (100 * correct / total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1tvrr8jX04T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# freezing the resnet by setting requires_grad to False for all parameters\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "# we need to know the number of features that are fed to the last dense layer\n",
        "num_features = model.fc.in_features\n",
        "\n",
        "# now we remove the ResNet18's classifier and replace it with a 10 classes classifier\n",
        "model.fc = nn.Linear(num_features, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}