{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_introduction_to_convnets_with_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningPyTorch1.x/blob/master/02_introduction_to_convnets_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKWpH3rxHD5P",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to Convolutional Neural Networks with PyTorch\n",
        "\n",
        "Similar to traditional Neural Networks, Convolutional Neural Networks are built using neurons but instead of only fully connected layers, convolutional networks have convolutional layers.\n",
        "\n",
        "\n",
        "So let's start by importing some standard modules and the MNIST dataset module. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqLIXx67Ol0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd4dpSQiTjml",
        "colab_type": "text"
      },
      "source": [
        "PyTorch is installed in Colab by default, but it's always a good practice to check what version we'll be working with. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81sTn8Eoeo1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "49537126-8d39-4a6f-b91b-ba52519b1f41"
      },
      "source": [
        "print('PyTorch version:', torch.__version__)\n",
        "print('Torchvision version:', torchvision.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.1.0\n",
            "Torchvision version: 0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1LQTo5gSLCa",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional and Pooling Layers\n",
        "\n",
        "A convolutional layer using pyTorch:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "torch.nn.Conv2d(num_in_channels, num_out_channels, kernel_size)\n",
        "```\n",
        "\n",
        "num_in_channels is the number of channels of the input tensor. If the previous layer is the input layer, num_in_channels is the number of channels of the image (3 channels for RGB images), otherwise num_in_channels is equal to the number of feature maps of the previous layer.\n",
        "\n",
        "num_out_channels is the number of filters (feature extractor) that this layer will apply over the image or feature maps generated by the previous layer.\n",
        "\n",
        "So for instance, if we have an RGB image and we are going to apply 32 filters of 3x3:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "torch.nn.Conv2d(3, 32, 3)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo9I8y4XRn2h",
        "colab_type": "text"
      },
      "source": [
        "## A Simple Convolutional Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6IZxtIn5CnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_channels, num_classes):\n",
        "        super(BasicCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channels, 32, 3, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, stride=1, padding=0)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(3*3*64, 64, bias=True)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        x = F.relu(self.conv1(X))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.reshape(-1, 3*3*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTiUSbCjgrbd",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Datatset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uHVwNkggvi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03d8a4b9-12ad-4bd2-a952-e6292ca25144"
      },
      "source": [
        "dataset_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.1307], [0.3081])\n",
        "])\n",
        "\n",
        "train_set = MNIST('./mnist', train=True, download=True, transform=dataset_transform)\n",
        "test_set  = MNIST('./mnist', train=False, download=True, transform=dataset_transform)\n",
        "\n",
        "\n",
        "#let's check the size of our tensors\n",
        "print(train_set.data.shape)\n",
        "print(test_set.data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}